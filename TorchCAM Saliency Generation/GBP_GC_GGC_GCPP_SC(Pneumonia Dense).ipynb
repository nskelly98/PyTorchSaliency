{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"utu70TUTXlhY"},"outputs":[],"source":["!pip install torchcam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gs7xY9gndL3c"},"outputs":[],"source":["!pip install saliency"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_sxx_LU9nrL"},"outputs":[],"source":["!pip install captum"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KaA-upXlpz8v"},"outputs":[],"source":["import torch\n","from torchvision import models, transforms\n","from captum.attr import GuidedBackprop\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","import pandas as pd\n","from captum.attr import GuidedGradCam\n","import os\n","from matplotlib import pylab as P\n","import PIL.Image\n","import saliency.core as saliency"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yMPr1Kt4XIXC"},"outputs":[],"source":["\n","##### Specify Device\n","\n","device = torch.device(\"cpu\")\n","\n","if torch.cuda.is_available():\n","   print(\"Training on GPU\")\n","   device = torch.device(\"cuda:0\")\n"]},{"cell_type":"markdown","metadata":{"id":"tjJh7mFBwyPV"},"source":["#Preliminary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W3dB2Stb6-7h"},"outputs":[],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5mIX7MSvZrMV"},"outputs":[],"source":["\n","# Boilerplate methods.\n","def ShowImage(im, title='', ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im)\n","    P.title(title)\n","\n","def ShowGrayscaleImage(im, title='', ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im, cmap=P.cm.gray, vmin=0, vmax=1)\n","    P.title(title)\n","\n","def ShowHeatMap(im, title, ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im, cmap='inferno')\n","    P.title(title)\n","\n","def LoadImage(file_path):\n","    im = PIL.Image.open(file_path).convert('RGB')\n","    im = im.resize((224, 224))\n","    im = np.asarray(im)\n","    return im\n","\n","transformer = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","def PreprocessImagesNOBATCH(images):\n","    # assumes input is 4-D, with range [0,255]\n","    images = np.array(images)\n","    images = images/255\n","    #print(images.shape)\n","    images = images.reshape(1,224,224,3)\n","    images = np.transpose(images, (0,3,1,2))\n","    images = torch.tensor(images, dtype=torch.float32)\n","    images = images.to(device)\n","    images = transformer.forward(images)\n","    return images.requires_grad_(True)\n","\n","def PreprocessImages(images):\n","    # assumes input is 4-D, with range [0,255]\n","    images = np.array(images)\n","    images = images/255\n","    #print(images.shape)\n","    #images = images.reshape(1,299,299,3)\n","    images = np.transpose(images, (0,3,1,2))\n","    images = torch.tensor(images, dtype=torch.float32)\n","    images = transformer.forward(images)\n","    return images.requires_grad_(True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_gyDRXeOp57b"},"outputs":[],"source":["\n","# Load the pre-trained model\n","model = torch.load('/content/drive/MyDrive/Saliency Map Research 2023/Models/pneumonia_dense.pt')\n","model=model.to(device)\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BETYuRPFvGsO"},"outputs":[],"source":["# Register hooks for Grad-CAM, which uses the last convolution layer\n","conv_layer = model.features.denseblock4.denselayer16.conv2\n","conv_layer_outputs = {}\n","def conv_layer_forward(m, i, o):\n","    # move the RGB dimension to the last dimension\n","    conv_layer_outputs[saliency.base.CONVOLUTION_LAYER_VALUES] = torch.movedim(o.cpu(), 1, 3).detach().numpy()\n","def conv_layer_backward(m, i, o):\n","    # move the RGB dimension to the last dimension\n","    conv_layer_outputs[saliency.base.CONVOLUTION_OUTPUT_GRADIENTS] = torch.movedim(o[0].cpu(), 1, 3).detach().numpy()\n","\n","conv_layer.register_forward_hook(conv_layer_forward)\n","conv_layer.register_full_backward_hook(conv_layer_backward)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9kJTYgo9osaE"},"outputs":[],"source":["class_idx_str = 'class_idx_str'\n","def call_model_function(images, call_model_args=None, expected_keys=None):\n","    images = PreprocessImages(images)\n","    images = images.to(device)\n","    target_class_idx =  call_model_args[class_idx_str]\n","    output = model(images)\n","    m = torch.nn.Softmax(dim=1)\n","    output = m(output)\n","    if saliency.base.INPUT_OUTPUT_GRADIENTS in expected_keys:\n","        outputs = output[:,target_class_idx]\n","        grads = torch.autograd.grad(outputs, images, grad_outputs=torch.ones_like(outputs))\n","        grads = torch.movedim(grads[0].cpu(), 1, 3)\n","        gradients = grads.detach().numpy()\n","        return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n","    else:\n","        one_hot = torch.zeros_like(output)\n","        one_hot[:,target_class_idx] = 1\n","        model.zero_grad()\n","        output.backward(gradient=one_hot, retain_graph=True)\n","        return conv_layer_outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xgw-d8GWAi0j"},"outputs":[],"source":["#Count files in directory\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/GradCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"GradCAM:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/Guided Backprop'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"Guided Backprop:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/Guided GradCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"Guided GradCAM\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/GradCAM++'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"GradCAM++:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/ScoreCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"ScoreCAM:\", file_count)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j3ComgyNPF5A"},"outputs":[],"source":["\n","def make_labels(file_path):\n","  labels = pd.read_csv(file_path)\n","  labels = labels.drop(['x','y','width','height'], axis=1)\n","  labels = labels.drop_duplicates(\"patientId\")\n","  return labels\n","\n","labels = make_labels(\"/content/drive/MyDrive/Saliency Map Research 2023/Pneumonia Dataset/Pneumonia_Labels_Final_2.csv\")\n","patientId = labels['patientId'].tolist()\n","#lim_patientId = patientId[13390:]\n","\n","root = '/content/drive/MyDrive/Saliency Map Research 2023/Pneumonia Dataset/stage_2_train_images_png'\n"]},{"cell_type":"markdown","metadata":{"id":"tKHB4Gzqj3_q"},"source":["#Script\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"taDkctMVNTsU"},"outputs":[],"source":["from torchcam.methods import GradCAM, ScoreCAM, GradCAMpp\n","from torchcam.utils import overlay_mask\n","from torchvision.transforms.functional import normalize, resize, to_pil_image\n","from matplotlib import cm\n","import time\n","\n","model = torch.load('/content/drive/MyDrive/Saliency Map Research 2023/Models/pneumonia_dense.pt').eval()\n","model = model.to(device)\n","\n","start_time = time.time()\n","\n","counter = 0\n","\n","model.requires_grad_(True)\n","\n","for label in patientId:\n","\n","  counter += 1  # Increment the counter\n","\n","  if counter % 10 == 0:  # Display the count for every 10th image\n","       print(f\"Processing image {counter}/{len(patientId)}\")\n","\n","  path = os.path.join(root, label + '.dcm.jpg.png')\n","\n","  im = LoadImage(path)\n","  im_tensor = PreprocessImagesNOBATCH(im)\n","  predictions = model(im_tensor)\n","  predictions = predictions.detach().cpu().numpy()\n","  prediction_class = np.argmax(predictions[0])\n","  input_image = im_tensor\n","\n","  prediction_class = torch.tensor(prediction_class)\n","\n","  if torch.cuda.is_available():\n","      input_image = input_image.cuda()  # Move input tensor to GPU\n","\n","  ######Guided Back Propagation######\n","\n","  # Generate saliency map using Guided Backpropagation\n","  guided_backprop = GuidedBackprop(model)\n","  guided_backprop_map = guided_backprop.attribute(input_image, target=prediction_class)  # Specify the target class index\n","\n","  saliency_map_gbp = np.transpose(guided_backprop_map.squeeze().cpu().numpy(), (1, 2, 0))\n","\n","  ######GradCAM######\n","\n","  cam_extractor = GradCAM(model, target_layer=model.layer4[-1].conv3)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  img = to_pil_image(im)\n","\n","  cmap = cm.get_cmap(\"plasma\")\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_gc = overlay\n","\n","  ######Guided GradCAM######\n","\n","  saliency_map_ggc = saliency_map_gbp * saliency_map_gc\n","\n","  cam_extractor.remove_hooks()\n","\n","  ######GradCAM++######\n","\n","  cam_extractor = GradCAMpp(model, target_layer=model.layer4[-1].conv3)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_gcpp = overlay\n","\n","  cam_extractor.remove_hooks()\n","\n","  ######ScoreCAM######\n","\n","  cam_extractor = ScoreCAM(model, target_layer=model.layer4[-1].conv3)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_sc = overlay\n","\n","  cam_extractor.remove_hooks()\n","\n","  #Save the arrays\n","  torch.save(saliency_map_gbp, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/Guided Backprop', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_gc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/GradCAM', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_ggc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/Guided GradCAM', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_gcpp, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/GradCAM++', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_sc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/ScoreCAM', label + '_saliency_map.pt'))\n","\n","end_time = time.time()\n","execution_time = end_time - start_time\n","\n","print(\"Execution time:\", execution_time, \"seconds\")\n"]},{"cell_type":"markdown","metadata":{"id":"wBcwkaz9oso9"},"source":["#Visualize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AZGK9aHMcqv0"},"outputs":[],"source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gbp)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Guided Backpropagation', ax=P.subplot(ROWS, COLS, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"craFzcnDQO_T"},"outputs":[],"source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Grad CAM', ax=P.subplot(ROWS, COLS, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6APMbZ4NQQoK"},"outputs":[],"source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_ggc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Guided Grad CAM', ax=P.subplot(ROWS, COLS, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ezmuOp65QSQD"},"outputs":[],"source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gcpp)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Grad CAM++', ax=P.subplot(ROWS, COLS, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cHuDMqTwQT58"},"outputs":[],"source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_sc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Score CAM', ax=P.subplot(ROWS, COLS, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OIj9RNhjr-oG"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1RJbPwa-XXLbZx9HxqVXBQFtVFqfwij15","authorship_tag":"ABX9TyOXmzdViFFKTFiJPgL2cXJE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}