{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1wtYxJEH6v0aeWLtR_LAgXOMwoBeeJAtm","authorship_tag":"ABX9TyPc+a05W/PGmkh8x+WmR0Kn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torchcam"],"metadata":{"id":"utu70TUTXlhY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install saliency"],"metadata":{"id":"gs7xY9gndL3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install captum"],"metadata":{"id":"Y_sxx_LU9nrL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KaA-upXlpz8v"},"outputs":[],"source":["import torch\n","from torchvision import models, transforms\n","from captum.attr import GuidedBackprop\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","import pandas as pd\n","from captum.attr import GuidedGradCam\n","import os\n","from matplotlib import pylab as P\n","import PIL.Image\n","import saliency.core as saliency"]},{"cell_type":"code","source":["\n","##### Specify Device\n","\n","device = torch.device(\"cpu\")\n","\n","if torch.cuda.is_available():\n","   print(\"Training on GPU\")\n","   device = torch.device(\"cuda:0\")\n"],"metadata":{"id":"yMPr1Kt4XIXC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Preliminary"],"metadata":{"id":"tjJh7mFBwyPV"}},{"cell_type":"code","source":["\n","# Boilerplate methods.\n","def ShowImage(im, title='', ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im)\n","    P.title(title)\n","\n","def ShowGrayscaleImage(im, title='', ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im, cmap=P.cm.gray, vmin=0, vmax=1)\n","    P.title(title)\n","\n","def ShowHeatMap(im, title, ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im, cmap='plasma')\n","    P.title(title)\n","\n","def LoadImage(file_path):\n","    im = PIL.Image.open(file_path).convert('RGB')\n","    im = im.resize((299, 299))\n","    im = np.asarray(im)\n","    return im\n","\n","transformer = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","def PreprocessImagesNOBATCH(images):\n","    # assumes input is 4-D, with range [0,255]\n","    images = np.array(images)\n","    images = images/255\n","    #print(images.shape)\n","    images = images.reshape(1,299,299,3)\n","    images = np.transpose(images, (0,3,1,2))\n","    images = torch.tensor(images, dtype=torch.float32)\n","    images = images.to(device)\n","    images = transformer.forward(images)\n","    return images.requires_grad_(True)\n","\n","def PreprocessImages(images):\n","   # assumes input is 4-D, with range [0,255]\n","   images = np.array(images)\n","   images = images/255\n","   #print(images.shape)\n","   #images = images.reshape(1,299,299,3)\n","   images = np.transpose(images, (0,3,1,2))\n","   images = torch.tensor(images, dtype=torch.float32)\n","   images = transformer.forward(images)\n","   return images.requires_grad_(True)\n"],"metadata":{"id":"5mIX7MSvZrMV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Load the pre-trained model\n","model = torch.load('/content/drive/MyDrive/Saliency Map Research 2023/Models/pneumonia_inception.pt')\n","model = model.to(device)\n","model.eval()\n"],"metadata":{"id":"_gyDRXeOp57b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Register hooks for Grad-CAM, which uses the last convolution layer\n","conv_layer = model.Mixed_7c\n","conv_layer_outputs = {}\n","def conv_layer_forward(m, i, o):\n","    # move the RGB dimension to the last dimension\n","    conv_layer_outputs[saliency.base.CONVOLUTION_LAYER_VALUES] = torch.movedim(o.cpu(), 1, 3).detach().numpy()\n","def conv_layer_backward(m, i, o):\n","    # move the RGB dimension to the last dimension\n","    conv_layer_outputs[saliency.base.CONVOLUTION_OUTPUT_GRADIENTS] = torch.movedim(o[0].cpu(), 1, 3).detach().numpy()\n","\n","conv_layer.register_forward_hook(conv_layer_forward)\n","conv_layer.register_full_backward_hook(conv_layer_backward)"],"metadata":{"id":"BETYuRPFvGsO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_idx_str = 'class_idx_str'\n","def call_model_function(images, call_model_args=None, expected_keys=None):\n","    images = PreprocessImages(images)\n","    images = images.to(device)\n","    target_class_idx =  call_model_args[class_idx_str]\n","    output = model(images)\n","    m = torch.nn.Softmax(dim=1)\n","    output = m(output)\n","    if saliency.base.INPUT_OUTPUT_GRADIENTS in expected_keys:\n","        outputs = output[:,target_class_idx]\n","        grads = torch.autograd.grad(outputs, images, grad_outputs=torch.ones_like(outputs))\n","        grads = torch.movedim(grads[0].cpu(), 1, 3)\n","        gradients = grads.detach().numpy()\n","        return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n","    else:\n","        one_hot = torch.zeros_like(output)\n","        one_hot[:,target_class_idx] = 1\n","        model.zero_grad()\n","        output.backward(gradient=one_hot, retain_graph=True)\n","        return conv_layer_outputs"],"metadata":{"id":"9kJTYgo9osaE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Count files in directory\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/GradCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"GradCAM:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/Guided Backprop'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"Guided Backprop:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/Guided GradCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"Guided GradCAM\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/GradCAM++'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"GradCAM++:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/ScoreCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"ScoreCAM:\", file_count)"],"metadata":{"id":"Dauj9vpYwUzr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def make_labels(file_path):\n","  labels = pd.read_csv(file_path)\n","  labels = labels.drop(['x','y','width','height'], axis=1)\n","  labels = labels.drop_duplicates(\"patientId\")\n","  return labels\n","\n","labels = make_labels(\"/content/drive/MyDrive/Saliency Map Research 2023/Pneumonia Dataset/Pneumonia_Labels_Final_2.csv\")\n","patientId = labels['patientId'].tolist()\n","#lim_patientId = patientId\n","\n","root = '/content/drive/MyDrive/Saliency Map Research 2023/Pneumonia Dataset/stage_2_train_images_png'\n"],"metadata":{"id":"j3ComgyNPF5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# Original patient IDs\n","patientId = labels['patientId'].tolist()\n","#lim_patientId = patientId\n","\n","# Directory path\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/Guided Backprop'\n","\n","# Get the list of patient IDs in the directory\n","file_names = os.listdir(directory_path)\n","directory_patient_ids = [file_name.split('_')[0] for file_name in file_names]\n","\n","# Find the missing patient IDs\n","missing_patient_ids = [patient_id for patient_id in lim_patientId if patient_id not in directory_patient_ids]\n","\n","print(\"Missing patient IDs:\", missing_patient_ids)\n","print(len(missing_patient_ids))"],"metadata":{"id":"cBJ9usBy9yRZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#lim_patientId = missing_patient_ids"],"metadata":{"id":"ppnqid2--jgt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Script\n"],"metadata":{"id":"tKHB4Gzqj3_q"}},{"cell_type":"code","source":["from torchcam.methods import GradCAM, ScoreCAM, GradCAMpp\n","from torchcam.utils import overlay_mask\n","from torchvision.transforms.functional import normalize, resize, to_pil_image\n","from matplotlib import cm\n","import time\n","\n","model = torch.load('/content/drive/MyDrive/Saliency Map Research 2023/Models/pneumonia_inception.pt').eval()\n","model = model.to(device)\n","\n","start_time = time.time()\n","\n","counter = 0\n","\n","model.requires_grad_(True)\n","\n","for label in patientId:\n","\n","  counter += 1  # Increment the counter\n","\n","  if counter % 10 == 0:  # Display the count for every 10th image\n","       print(f\"Processing image {counter}/{len(lim_patientId)}\")\n","\n","  path = os.path.join(root, label + '.dcm.jpg.png')\n","\n","  im = LoadImage(path)\n","  im_tensor = PreprocessImagesNOBATCH(im)\n","  predictions = model(im_tensor)\n","  predictions = predictions.detach().cpu().numpy()\n","  prediction_class = np.argmax(predictions[0])\n","  input_image = im_tensor\n","\n","  prediction_class = torch.tensor(prediction_class)\n","\n","  if torch.cuda.is_available():\n","      input_image = input_image.cuda()  # Move input tensor to GPU\n","\n","  ######Guided Back Propagation######\n","\n","  # Generate saliency map using Guided Backpropagation\n","  guided_backprop = GuidedBackprop(model)\n","  guided_backprop_map = guided_backprop.attribute(input_image, target=prediction_class)  # Specify the target class index\n","\n","  saliency_map_gbp = np.transpose(guided_backprop_map.squeeze().cpu().numpy(), (1, 2, 0))\n","\n","  ######GradCAM######\n","\n","  cam_extractor = GradCAM(model, target_layer=model.Mixed_7c)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  img = to_pil_image(im)\n","\n","  cmap = cm.get_cmap(\"plasma\")\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_gc = overlay\n","\n","  ######Guided GradCAM######\n","\n","  saliency_map_ggc = saliency_map_gbp * saliency_map_gc\n","\n","  cam_extractor.remove_hooks()\n","\n","  ######GradCAM++######\n","\n","  cam_extractor = GradCAMpp(model, target_layer=model.Mixed_7c)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_gcpp = overlay\n","\n","  cam_extractor.remove_hooks()\n","\n","  ######ScoreCAM######\n","\n","  cam_extractor = ScoreCAM(model, target_layer=model.Mixed_7c)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_sc = overlay\n","\n","  cam_extractor.remove_hooks()\n","\n","  #Save the arrays\n","  torch.save(saliency_map_gbp, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/Guided Backprop', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_gc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/GradCAM', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_ggc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/Guided GradCAM', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_gcpp, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/GradCAM++', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_sc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/ScoreCAM', label + '_saliency_map.pt'))\n","\n","end_time = time.time()\n","execution_time = end_time - start_time\n","\n","print(\"Execution time:\", execution_time, \"seconds\")\n"],"metadata":{"id":"taDkctMVNTsU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Visualize"],"metadata":{"id":"wBcwkaz9oso9"}},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gbp)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Guided Backpropagation', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"AZGK9aHMcqv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Grad CAM', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"craFzcnDQO_T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_ggc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Guided Grad CAM', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"6APMbZ4NQQoK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gcpp)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Grad CAM++', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"ezmuOp65QSQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_sc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Score CAM', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"cHuDMqTwQT58"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Torchcam GradCAM\n","\n"],"metadata":{"id":"phRXMvV-F5yL"}},{"cell_type":"code","source":["from torchcam.methods import GradCAM, ScoreCAM, GradCAMpp\n","import torch\n","from torchvision.models import resnet50\n","from PIL import Image\n","from torchvision.models import resnet18\n","\n","model = torch.load('/content/drive/MyDrive/Saliency Map Research 2023/Models/pneumonia_inception.pt').eval()\n","model = model.to(device)\n","for label in lim_patientId:\n","\n","  path = os.path.join(root, label + '.dcm.jpg.png')\n","\n","  im = LoadImage(path)\n","  im_tensor = PreprocessImagesNOBATCH(im)\n","  predictions = model(im_tensor)\n","  predictions = predictions.detach().cpu().numpy()\n","  prediction_class = np.argmax(predictions[0])\n","  input_image = im_tensor\n","\n","  prediction_class = torch.tensor(prediction_class)\n","\n","  # Generate saliency map using Guided Backpropagation\n","  cam_extractor = GradCAM(model)\n","                          #target_layer = 'Mixed_7c.branch_pool.conv')\n","  #saliency_map = cam(input_image, prediction_class)  # Specify the target class index\n","\n","  out = model(input_image)\n","  cams = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","\n","  #with GradCAM(model) as cam_extractor:\n","  # Preprocess your data and feed it to the model\n","  #  out = model(input_image.unsqueeze(0))\n","  # Retrieve the CAM by passing the class index and the model output\n","  #  activation_map = cam_extractor(out.squeeze(0).argmax().item(), out)"],"metadata":{"id":"oi-SzFK_5Tzx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for cam in cams:\n","  print(cam)"],"metadata":{"id":"3WNKFxJHh1en"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name, cam in zip(cam_extractor.target_names, cams):\n","  plt.imshow(cam.squeeze(0).cpu().numpy(), cmap = 'plasma')\n","  plt.axis('off')\n","  plt.title('TorchCAM GradCAM (No Smoothing)')\n","  plt.show()"],"metadata":{"id":"tAlMIdIyh6Ik"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchcam.utils import overlay_mask\n","from torchvision.transforms.functional import normalize, resize, to_pil_image\n","\n","# Overlayed on the image\n","for name, cam in zip(cam_extractor.target_names, cams):\n","  result = overlay_mask(to_pil_image(im), to_pil_image(cam.squeeze(0), mode='F'), colormap = 'plasma', alpha=0.5)\n","  plt.imshow(result); plt.axis('off'); plt.title(name); plt.show()"],"metadata":{"id":"vwzztcIyidqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(cam.squeeze(0))"],"metadata":{"id":"vRQGe8Slhd0U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cam_extractor.remove_hooks()"],"metadata":{"id":"5x7M_iZebKEw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from matplotlib import cm\n","\n","img = to_pil_image(im)\n","\n","cmap = cm.get_cmap(\"plasma\")\n","\n","mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","overlay = cmap(np.asarray(overlay) ** 2)\n","print(overlay)\n","overlay = overlay[:,:,:3]\n","#overlay = (255 * cmap(np.asarray(overlay) ** 2)[:, :, :3]).astype(np.uint8)\n","\n","plt.imshow(overlay, cmap = 'plasma')\n","plt.axis('off')\n","plt.title('TorchCAM GradCAM (Smoothing)')\n","plt.show()"],"metadata":{"id":"L2Ca_AyCZk_l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(overlay)"],"metadata":{"id":"aqRzXV-4dkKx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Torchcam Guided GradCAM"],"metadata":{"id":"yQDpimP3ZXau"}},{"cell_type":"code","source":["print(saliency_map_gbp)"],"metadata":{"id":"k_P9E8lv0K2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ggc = overlay * saliency_map_gbp\n","\n","ggc_mask_grayscale = saliency.VisualizeImageGrayscale(ggc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(ggc_mask_grayscale, title='Guided GradCAM Torchcam', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"dLkXrlWggzuT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uWf_cjKyzz9i"},"execution_count":null,"outputs":[]}]}