{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1bxILPdaeP-3XYzuAn7TvDTCAOczTF-n9","authorship_tag":"ABX9TyMRKSXafNVXtduay2AwwDcC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torchcam"],"metadata":{"id":"utu70TUTXlhY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install saliency"],"metadata":{"id":"gs7xY9gndL3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install captum"],"metadata":{"id":"Y_sxx_LU9nrL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KaA-upXlpz8v"},"outputs":[],"source":["import torch\n","from torchvision import models, transforms\n","from captum.attr import GuidedBackprop\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","import pandas as pd\n","from captum.attr import GuidedGradCam\n","import os\n","from matplotlib import pylab as P\n","import PIL.Image\n","import saliency.core as saliency"]},{"cell_type":"code","source":["\n","##### Specify Device\n","\n","device = torch.device(\"cpu\")\n","\n","if torch.cuda.is_available():\n","   print(\"Training on GPU\")\n","   device = torch.device(\"cuda:0\")\n"],"metadata":{"id":"yMPr1Kt4XIXC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Preliminary"],"metadata":{"id":"tjJh7mFBwyPV"}},{"cell_type":"code","source":["\n","# Boilerplate methods.\n","def ShowImage(im, title='', ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im)\n","    P.title(title)\n","\n","def ShowGrayscaleImage(im, title='', ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im, cmap=P.cm.gray, vmin=0, vmax=1)\n","    P.title(title)\n","\n","def ShowHeatMap(im, title, ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im, cmap='plasma')\n","    P.title(title)\n","\n","def LoadImage(file_path):\n","    im = PIL.Image.open(file_path).convert('RGB')\n","    im = im.resize((299, 299))\n","    im = np.asarray(im)\n","    return im\n","\n","transformer = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","def PreprocessImagesNOBATCH(images):\n","    # assumes input is 4-D, with range [0,255]\n","    images = np.array(images)\n","    images = images/255\n","    #print(images.shape)\n","    images = images.reshape(1,299,299,3)\n","    images = np.transpose(images, (0,3,1,2))\n","    images = torch.tensor(images, dtype=torch.float32)\n","    images = images.to(device)\n","    images = transformer.forward(images)\n","    return images.requires_grad_(True)\n","\n","def PreprocessImages(images):\n","   # assumes input is 4-D, with range [0,255]\n","   images = np.array(images)\n","   images = images/255\n","   #print(images.shape)\n","   #images = images.reshape(1,299,299,3)\n","   images = np.transpose(images, (0,3,1,2))\n","   images = torch.tensor(images, dtype=torch.float32)\n","   images = transformer.forward(images)\n","   return images.requires_grad_(True)\n"],"metadata":{"id":"5mIX7MSvZrMV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Load the pre-trained model\n","model = torch.load('/content/drive/MyDrive/Saliency Map Research 2023/Models/thorax_inception.pt')\n","model = model.to(device)\n","model.eval()\n"],"metadata":{"id":"_gyDRXeOp57b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Register hooks for Grad-CAM, which uses the last convolution layer\n","conv_layer = model.Mixed_7c\n","conv_layer_outputs = {}\n","def conv_layer_forward(m, i, o):\n","    # move the RGB dimension to the last dimension\n","    conv_layer_outputs[saliency.base.CONVOLUTION_LAYER_VALUES] = torch.movedim(o.cpu(), 1, 3).detach().numpy()\n","def conv_layer_backward(m, i, o):\n","    # move the RGB dimension to the last dimension\n","    conv_layer_outputs[saliency.base.CONVOLUTION_OUTPUT_GRADIENTS] = torch.movedim(o[0].cpu(), 1, 3).detach().numpy()\n","\n","conv_layer.register_forward_hook(conv_layer_forward)\n","conv_layer.register_full_backward_hook(conv_layer_backward)"],"metadata":{"id":"BETYuRPFvGsO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_idx_str = 'class_idx_str'\n","def call_model_function(images, call_model_args=None, expected_keys=None):\n","    images = PreprocessImages(images)\n","    images = images.to(device)\n","    target_class_idx =  call_model_args[class_idx_str]\n","    output = model(images)\n","    m = torch.nn.Softmax(dim=1)\n","    output = m(output)\n","    if saliency.base.INPUT_OUTPUT_GRADIENTS in expected_keys:\n","        outputs = output[:,target_class_idx]\n","        grads = torch.autograd.grad(outputs, images, grad_outputs=torch.ones_like(outputs))\n","        grads = torch.movedim(grads[0].cpu(), 1, 3)\n","        gradients = grads.detach().numpy()\n","        return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n","    else:\n","        one_hot = torch.zeros_like(output)\n","        one_hot[:,target_class_idx] = 1\n","        model.zero_grad()\n","        output.backward(gradient=one_hot, retain_graph=True)\n","        return conv_layer_outputs"],"metadata":{"id":"9kJTYgo9osaE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Count files in directory\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumothorax Inception (Tensor)/GradCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"GradCAM:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumothorax Inception (Tensor)/Guided Backprop'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"Guided Backprop:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumothorax Inception (Tensor)/Guided GradCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"Guided GradCAM\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumothorax Inception (Tensor)/GradCAM++'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"GradCAM++:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumothorax Inception (Tensor)/ScoreCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"ScoreCAM:\", file_count)"],"metadata":{"id":"Dauj9vpYwUzr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumothorax Inception (Tensor)/GradCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"GradCAM:\", file_count)"],"metadata":{"id":"uiomUGG1_ABj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","labels = pd.read_csv(\"/content/drive/MyDrive/Saliency Map Research 2023/Pneumothorax Dataset/Pneumothorax_Labels_Final.csv\")\n","labels = labels.drop_duplicates(\"ImageId\")\n","patientId = labels['ImageId'].tolist()\n","#lim_patientId = patientId[8880:]\n","\n","root = '/content/drive/MyDrive/Saliency Map Research 2023/Pneumothorax Dataset/images_png/PNG/train'\n"],"metadata":{"id":"j3ComgyNPF5A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Script\n"],"metadata":{"id":"tKHB4Gzqj3_q"}},{"cell_type":"code","source":["from torchcam.methods import GradCAM, ScoreCAM, GradCAMpp\n","from torchcam.utils import overlay_mask\n","from torchvision.transforms.functional import normalize, resize, to_pil_image\n","from matplotlib import cm\n","import time\n","\n","model = torch.load('/content/drive/MyDrive/Saliency Map Research 2023/Models/pneumonia_inception.pt').eval()\n","model = model.to(device)\n","\n","start_time = time.time()\n","\n","counter = 0\n","\n","model.requires_grad_(True)\n","\n","for label in patientId:\n","\n","  counter += 1  # Increment the counter\n","\n","  if counter % 10 == 0:  # Display the count for every 10th image\n","       print(f\"Processing image {counter}/{len(patientId)}\")\n","\n","  path = os.path.join(root, label + '.png')\n","\n","  im = LoadImage(path)\n","  im_tensor = PreprocessImagesNOBATCH(im)\n","  predictions = model(im_tensor)\n","  predictions = predictions.detach().cpu().numpy()\n","  prediction_class = np.argmax(predictions[0])\n","  input_image = im_tensor\n","\n","  prediction_class = torch.tensor(prediction_class)\n","\n","  if torch.cuda.is_available():\n","      input_image = input_image.cuda()  # Move input tensor to GPU\n","\n","  ######Guided Back Propagation######\n","\n","  # Generate saliency map using Guided Backpropagation\n","  guided_backprop = GuidedBackprop(model)\n","  guided_backprop_map = guided_backprop.attribute(input_image, target=prediction_class)  # Specify the target class index\n","\n","  saliency_map_gbp = np.transpose(guided_backprop_map.squeeze().cpu().numpy(), (1, 2, 0))\n","\n","  ######GradCAM######\n","\n","  cam_extractor = GradCAM(model, target_layer=model.Mixed_7c)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  img = to_pil_image(im)\n","\n","  cmap = cm.get_cmap(\"plasma\")\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_gc = overlay\n","\n","  ######Guided GradCAM######\n","\n","  saliency_map_ggc = saliency_map_gbp * saliency_map_gc\n","\n","  cam_extractor.remove_hooks()\n","\n","  ######GradCAM++######\n","\n","  cam_extractor = GradCAMpp(model, target_layer=model.Mixed_7c)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_gcpp = overlay\n","\n","  cam_extractor.remove_hooks()\n","\n","  ######ScoreCAM######\n","\n","  cam_extractor = ScoreCAM(model, target_layer=model.Mixed_7c)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_sc = overlay\n","\n","  cam_extractor.remove_hooks()\n","\n","  #Save the arrays\n","  torch.save(saliency_map_gbp, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumothorax Inception (Tensor)/Guided Backprop', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_gc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumothorax Inception (Tensor)/GradCAM', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_ggc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumothorax Inception (Tensor)/Guided GradCAM', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_gcpp, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumothorax Inception (Tensor)/GradCAM++', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_sc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumothorax Inception (Tensor)/ScoreCAM', label + '_saliency_map.pt'))\n","\n","end_time = time.time()\n","execution_time = end_time - start_time\n","\n","print(\"Execution time:\", execution_time, \"seconds\")\n"],"metadata":{"id":"taDkctMVNTsU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Visualize"],"metadata":{"id":"wBcwkaz9oso9"}},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gbp)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Guided Backpropagation', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"AZGK9aHMcqv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Grad CAM', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"craFzcnDQO_T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_ggc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Guided Grad CAM', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"6APMbZ4NQQoK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gcpp)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Grad CAM++', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"ezmuOp65QSQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_sc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Score CAM', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"cHuDMqTwQT58"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uWf_cjKyzz9i"},"execution_count":null,"outputs":[]}]}