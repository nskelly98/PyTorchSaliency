{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1wtYxJEH6v0aeWLtR_LAgXOMwoBeeJAtm","authorship_tag":"ABX9TyPc+a05W/PGmkh8x+WmR0Kn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torchcam"],"metadata":{"id":"utu70TUTXlhY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689784209715,"user_tz":240,"elapsed":4412,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"}},"outputId":"1f373b16-b33c-401d-9e8a-6d729af1540b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchcam in /usr/local/lib/python3.10/dist-packages (0.3.2)\n","Requirement already satisfied: torch<2.0.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from torchcam) (1.13.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from torchcam) (1.22.4)\n","Requirement already satisfied: Pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from torchcam) (8.4.0)\n","Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from torchcam) (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->torchcam) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->torchcam) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->torchcam) (4.41.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->torchcam) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->torchcam) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->torchcam) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->torchcam) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.0.0,>=1.7.0->torchcam) (4.7.1)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<2.0.0,>=1.7.0->torchcam) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch<2.0.0,>=1.7.0->torchcam) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch<2.0.0,>=1.7.0->torchcam) (11.10.3.66)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<2.0.0,>=1.7.0->torchcam) (11.7.99)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0,>=1.7.0->torchcam) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0,>=1.7.0->torchcam) (0.40.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->torchcam) (1.16.0)\n"]}]},{"cell_type":"code","source":["!pip install saliency"],"metadata":{"id":"gs7xY9gndL3c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689784226127,"user_tz":240,"elapsed":9198,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"}},"outputId":"4d791eb9-0391-49ae-b495-79cbc03a5761"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: saliency in /usr/local/lib/python3.10/dist-packages (0.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from saliency) (1.22.4)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from saliency) (0.19.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (1.10.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (3.1)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (8.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (2.25.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (2023.7.10)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (23.1)\n"]}]},{"cell_type":"code","source":["!pip install captum"],"metadata":{"id":"Y_sxx_LU9nrL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689784233862,"user_tz":240,"elapsed":7738,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"}},"outputId":"ab20d1e0-5b19-4346-d70e-6f2daee3932f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: captum in /usr/local/lib/python3.10/dist-packages (0.6.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.22.4)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (1.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.7.1)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (11.10.3.66)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (11.7.99)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6->captum) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6->captum) (0.40.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.41.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KaA-upXlpz8v","executionInfo":{"status":"ok","timestamp":1689784237994,"user_tz":240,"elapsed":4136,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"906620b8-6878-4115-e179-8dc50aa2d912"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n","  warn(\n"]}],"source":["import torch\n","from torchvision import models, transforms\n","from captum.attr import GuidedBackprop\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","import pandas as pd\n","from captum.attr import GuidedGradCam\n","import os\n","from matplotlib import pylab as P\n","import PIL.Image\n","import saliency.core as saliency"]},{"cell_type":"code","source":["\n","##### Specify Device\n","\n","device = torch.device(\"cpu\")\n","\n","if torch.cuda.is_available():\n","   print(\"Training on GPU\")\n","   device = torch.device(\"cuda:0\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yMPr1Kt4XIXC","executionInfo":{"status":"ok","timestamp":1689784237995,"user_tz":240,"elapsed":5,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"}},"outputId":"fcfae8eb-e0d9-4736-c208-0c89e09f3097"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on GPU\n"]}]},{"cell_type":"markdown","source":["#Preliminary"],"metadata":{"id":"tjJh7mFBwyPV"}},{"cell_type":"code","source":["\n","# Boilerplate methods.\n","def ShowImage(im, title='', ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im)\n","    P.title(title)\n","\n","def ShowGrayscaleImage(im, title='', ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im, cmap=P.cm.gray, vmin=0, vmax=1)\n","    P.title(title)\n","\n","def ShowHeatMap(im, title, ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im, cmap='plasma')\n","    P.title(title)\n","\n","def LoadImage(file_path):\n","    im = PIL.Image.open(file_path).convert('RGB')\n","    im = im.resize((299, 299))\n","    im = np.asarray(im)\n","    return im\n","\n","transformer = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","def PreprocessImagesNOBATCH(images):\n","    # assumes input is 4-D, with range [0,255]\n","    images = np.array(images)\n","    images = images/255\n","    #print(images.shape)\n","    images = images.reshape(1,299,299,3)\n","    images = np.transpose(images, (0,3,1,2))\n","    images = torch.tensor(images, dtype=torch.float32)\n","    images = images.to(device)\n","    images = transformer.forward(images)\n","    return images.requires_grad_(True)\n","\n","def PreprocessImages(images):\n","   # assumes input is 4-D, with range [0,255]\n","   images = np.array(images)\n","   images = images/255\n","   #print(images.shape)\n","   #images = images.reshape(1,299,299,3)\n","   images = np.transpose(images, (0,3,1,2))\n","   images = torch.tensor(images, dtype=torch.float32)\n","   images = transformer.forward(images)\n","   return images.requires_grad_(True)\n"],"metadata":{"id":"5mIX7MSvZrMV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Load the pre-trained model\n","model = torch.load('/content/drive/MyDrive/Saliency Map Research 2023/Models/pneumonia_inception.pt')\n","model = model.to(device)\n","model.eval()\n"],"metadata":{"id":"_gyDRXeOp57b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689784239955,"user_tz":240,"elapsed":1963,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"}},"outputId":"5f001fa0-9f04-4050-c384-78bf2fa853c7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Inception3(\n","  (Conv2d_1a_3x3): BasicConv2d(\n","    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_2a_3x3): BasicConv2d(\n","    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_2b_3x3): BasicConv2d(\n","    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (Conv2d_3b_1x1): BasicConv2d(\n","    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_4a_3x3): BasicConv2d(\n","    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (Mixed_5b): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_5c): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_5d): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6a): InceptionB(\n","    (branch3x3): BasicConv2d(\n","      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6b): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6c): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6d): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6e): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (AuxLogits): InceptionAux(\n","    (conv0): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (conv1): BasicConv2d(\n","      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (fc): Linear(in_features=768, out_features=2, bias=True)\n","  )\n","  (Mixed_7a): InceptionD(\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2): BasicConv2d(\n","      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_4): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_7b): InceptionE(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_7c): InceptionE(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Register hooks for Grad-CAM, which uses the last convolution layer\n","conv_layer = model.Mixed_7c\n","conv_layer_outputs = {}\n","def conv_layer_forward(m, i, o):\n","    # move the RGB dimension to the last dimension\n","    conv_layer_outputs[saliency.base.CONVOLUTION_LAYER_VALUES] = torch.movedim(o.cpu(), 1, 3).detach().numpy()\n","def conv_layer_backward(m, i, o):\n","    # move the RGB dimension to the last dimension\n","    conv_layer_outputs[saliency.base.CONVOLUTION_OUTPUT_GRADIENTS] = torch.movedim(o[0].cpu(), 1, 3).detach().numpy()\n","\n","conv_layer.register_forward_hook(conv_layer_forward)\n","conv_layer.register_full_backward_hook(conv_layer_backward)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BETYuRPFvGsO","executionInfo":{"status":"ok","timestamp":1689784239956,"user_tz":240,"elapsed":26,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"}},"outputId":"97907b59-1ad7-4e9c-9bcc-a948f972ead0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.utils.hooks.RemovableHandle at 0x7ee63cb53550>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["class_idx_str = 'class_idx_str'\n","def call_model_function(images, call_model_args=None, expected_keys=None):\n","    images = PreprocessImages(images)\n","    images = images.to(device)\n","    target_class_idx =  call_model_args[class_idx_str]\n","    output = model(images)\n","    m = torch.nn.Softmax(dim=1)\n","    output = m(output)\n","    if saliency.base.INPUT_OUTPUT_GRADIENTS in expected_keys:\n","        outputs = output[:,target_class_idx]\n","        grads = torch.autograd.grad(outputs, images, grad_outputs=torch.ones_like(outputs))\n","        grads = torch.movedim(grads[0].cpu(), 1, 3)\n","        gradients = grads.detach().numpy()\n","        return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n","    else:\n","        one_hot = torch.zeros_like(output)\n","        one_hot[:,target_class_idx] = 1\n","        model.zero_grad()\n","        output.backward(gradient=one_hot, retain_graph=True)\n","        return conv_layer_outputs"],"metadata":{"id":"9kJTYgo9osaE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Count files in directory\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/GradCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"GradCAM:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/Guided Backprop'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"Guided Backprop:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/Guided GradCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"Guided GradCAM\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/GradCAM++'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"GradCAM++:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/ScoreCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"ScoreCAM:\", file_count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dauj9vpYwUzr","executionInfo":{"status":"ok","timestamp":1689784505176,"user_tz":240,"elapsed":30879,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"}},"outputId":"623f92d4-d88d-448d-a711-19d4f4669e3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GradCAM: 14861\n","Guided Backprop: 14861\n","Guided GradCAM 14861\n","GradCAM++: 14861\n","ScoreCAM: 14861\n"]}]},{"cell_type":"code","source":["\n","def make_labels(file_path):\n","  labels = pd.read_csv(file_path)\n","  labels = labels.drop(['x','y','width','height'], axis=1)\n","  labels = labels.drop_duplicates(\"patientId\")\n","  return labels\n","\n","labels = make_labels(\"/content/drive/MyDrive/Saliency Map Research 2023/Pneumonia Dataset/Pneumonia_Labels_Final_2.csv\")\n","patientId = labels['patientId'].tolist()\n","#lim_patientId = patientId\n","\n","root = '/content/drive/MyDrive/Saliency Map Research 2023/Pneumonia Dataset/stage_2_train_images_png'\n"],"metadata":{"id":"j3ComgyNPF5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# Original patient IDs\n","patientId = labels['patientId'].tolist()\n","#lim_patientId = patientId\n","\n","# Directory path\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/Guided Backprop'\n","\n","# Get the list of patient IDs in the directory\n","file_names = os.listdir(directory_path)\n","directory_patient_ids = [file_name.split('_')[0] for file_name in file_names]\n","\n","# Find the missing patient IDs\n","missing_patient_ids = [patient_id for patient_id in lim_patientId if patient_id not in directory_patient_ids]\n","\n","print(\"Missing patient IDs:\", missing_patient_ids)\n","print(len(missing_patient_ids))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBJ9usBy9yRZ","executionInfo":{"status":"ok","timestamp":1689784242592,"user_tz":240,"elapsed":1940,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"}},"outputId":"c6fadf49-22f1-44be-f6d8-7639a149521c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Missing patient IDs: ['aaa685a7-16f1-448e-af0f-a06867f78e1c', '5eaecf07-fe6e-4503-a7d9-3b99d344d08a', 'a2990f44-8592-4427-b704-b19565a0bedd', '5150b314-97cd-4721-9f03-a8d701822630', '5d8dbcf9-0d68-4aec-8638-b0a9f45d71d6', '0b5fa34f-5c96-4cc5-becc-317acdff3221', 'f1c8caa2-a6dc-40c0-ab85-4769688f1eec', '4455076a-577d-4531-afed-17f91bca0ffc', 'f630809e-2498-44af-beaa-dda23a36cf20', 'f01a7f1d-e30c-4114-889f-0ba7547a2479', '6dad7d7d-5e28-408b-9315-a74c48d88097', 'abd4e52c-39a9-401d-b0ee-7d94f4597fae', 'cd1d42a0-e085-4f64-baaf-1da212416e8d', '7f9623a6-510f-4e84-8e58-12b65a5e9dfc', 'a42380cd-d65c-479d-b4ea-cf04a147efc4', 'b3cbe758-859f-4ace-8968-4953ca48dfc7', '091cc2b7-8ba6-4fce-8ae2-7547117dbddf', '076149ed-e1a7-4424-b283-18161c95e0e2', 'b1c27227-035d-4fdc-a6fb-89bba42ae359', '5dad8463-531e-4945-8aab-058a63127c4e', 'cc455bfc-0efb-418e-a45d-c42723afd6b8', '528d7356-ba8d-4d21-934c-9557d0fe197f', 'dbc1e726-39b3-4df1-988e-ed7119a4eaa0', 'd861e6e0-6c55-4f1b-8959-e89c2c999334', '6ed71d2f-d2e1-40c5-b750-5b25b302915b', 'a8fc77b2-a30c-4360-b716-74bb97685c58', 'bc59d7f5-e65b-4cc1-a668-4517ab02d974', 'b46fcbd0-8851-4561-96de-0a820e49f45d', 'ace01ccc-dbc9-4d12-b6c4-6ca3dcafe11e', 'b26cc8d8-a11b-4b2f-ad69-41ad37ad5c53', 'd716617f-d655-4127-ace8-18189299a28c', '56bab623-fa84-4335-8874-773e5f6c966c', '697491a0-2dfb-4d33-ace5-e824a637215f', '11a2e0cb-ee1f-4d53-a211-b8faff6bf888', 'b6138fc8-c652-4b7f-978d-895d10b0a0ea', '68c87e83-8ab6-412a-b0bb-25b4e1d1e678', '2090a3aa-9ba3-42a2-baa3-f0bfa4f783f8', '9272f957-f709-4f8b-929a-643c4e461d48', '7a391371-52fb-4f1b-af7d-3305c528d33d', 'a2269867-3a23-4cd4-80ec-8c0f917f5986', '8bccfbc7-b7c4-41f6-9e43-53dc569dd2e4', '11ff35a5-51dc-41d7-afe1-588ff59cbc4b', '459dec9a-7d3b-40a3-a6ec-5b50f84529c6', 'b9a05d0d-8f3f-40db-8114-c3fd1a4792b0', 'dc4d3a01-94f5-4e5a-a843-1c60dfd8b352', '524ca5ff-4301-43ec-8a17-3682f5edb548', '56e71de6-3204-4dae-ae32-09065d622023', '69e0c05a-89e0-4b26-9628-7276cf4c18d8', '629c147a-375d-4776-a230-57ef6892468f', '86469e34-c9ba-4ec9-bbe0-6d04535122a0', '7fc19f9d-a178-43d6-a63b-7706eb334147', '5f0afe6f-1a23-48b6-9c7a-aeeba030e41a', 'b82ca47e-0053-4a1a-9692-1d3a58f52bb3', '9042bce5-f59b-4b28-b9af-49dd5a717f5a', '6520137b-c98c-42be-9689-dbce52e1df6b', '8e287c3f-3484-4a12-a58d-ac4a4c077bae', '82fe1495-d984-4693-9220-1a3eb1a03ccb', 'af0cb664-287b-47b7-b7f6-55518a510ebf', '3db17fd0-1423-41a0-9ae6-41f8c864caca', '76f00430-861f-4370-9e06-dd5b9692b669', '2dd692a5-a60c-443e-8299-af5d03949b60', 'b9e5b5ab-0f77-418d-bd5b-ecce5da142e8', '9d726da1-e0cc-4262-9b8e-10b0faf32f3b', '4c75d5dd-63d8-4678-9f22-61340ca246db', 'd85df86d-20bb-478b-8ad3-bd9dd4c132ab', '77633bed-c31b-466a-946d-6624b97231a8', '851e42c6-2d78-4dbf-9297-0ebda7f6bfe8', '77e9a287-61ee-4686-b029-c7e1b09b7dbb', '77158193-070f-420c-aa5a-1610601ef4ce', '98fdc812-0134-423f-8da2-04d95fe2f839', '42ce26f3-8606-4143-9fbc-70d461ce377b', 'f73ff426-6e28-476e-82c6-31d3603a1cc3', 'ac38e730-300e-4267-88ec-5247c0b90ed5', '214dcd68-4220-4010-8510-4c8eee830c70', '57c51bb2-7795-48a1-8f14-e16e7c0ee3eb', '44db1d69-388e-4268-849e-852c1f092a01', '320e8587-ab3c-47d0-9a89-fcc2f5cb5c95', '3ea67d3a-90be-4e77-a745-a9e323189097']\n","78\n"]}]},{"cell_type":"code","source":["#lim_patientId = missing_patient_ids"],"metadata":{"id":"ppnqid2--jgt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Script\n"],"metadata":{"id":"tKHB4Gzqj3_q"}},{"cell_type":"code","source":["from torchcam.methods import GradCAM, ScoreCAM, GradCAMpp\n","from torchcam.utils import overlay_mask\n","from torchvision.transforms.functional import normalize, resize, to_pil_image\n","from matplotlib import cm\n","import time\n","\n","model = torch.load('/content/drive/MyDrive/Saliency Map Research 2023/Models/pneumonia_inception.pt').eval()\n","model = model.to(device)\n","\n","start_time = time.time()\n","\n","counter = 0\n","\n","model.requires_grad_(True)\n","\n","for label in patientId:\n","\n","  counter += 1  # Increment the counter\n","\n","  if counter % 10 == 0:  # Display the count for every 10th image\n","       print(f\"Processing image {counter}/{len(lim_patientId)}\")\n","\n","  path = os.path.join(root, label + '.dcm.jpg.png')\n","\n","  im = LoadImage(path)\n","  im_tensor = PreprocessImagesNOBATCH(im)\n","  predictions = model(im_tensor)\n","  predictions = predictions.detach().cpu().numpy()\n","  prediction_class = np.argmax(predictions[0])\n","  input_image = im_tensor\n","\n","  prediction_class = torch.tensor(prediction_class)\n","\n","  if torch.cuda.is_available():\n","      input_image = input_image.cuda()  # Move input tensor to GPU\n","\n","  ######Guided Back Propagation######\n","\n","  # Generate saliency map using Guided Backpropagation\n","  guided_backprop = GuidedBackprop(model)\n","  guided_backprop_map = guided_backprop.attribute(input_image, target=prediction_class)  # Specify the target class index\n","\n","  saliency_map_gbp = np.transpose(guided_backprop_map.squeeze().cpu().numpy(), (1, 2, 0))\n","\n","  ######GradCAM######\n","\n","  cam_extractor = GradCAM(model, target_layer=model.Mixed_7c)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  img = to_pil_image(im)\n","\n","  cmap = cm.get_cmap(\"plasma\")\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_gc = overlay\n","\n","  ######Guided GradCAM######\n","\n","  saliency_map_ggc = saliency_map_gbp * saliency_map_gc\n","\n","  cam_extractor.remove_hooks()\n","\n","  ######GradCAM++######\n","\n","  cam_extractor = GradCAMpp(model, target_layer=model.Mixed_7c)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_gcpp = overlay\n","\n","  cam_extractor.remove_hooks()\n","\n","  ######ScoreCAM######\n","\n","  cam_extractor = ScoreCAM(model, target_layer=model.Mixed_7c)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_sc = overlay\n","\n","  cam_extractor.remove_hooks()\n","\n","  #Save the arrays\n","  torch.save(saliency_map_gbp, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/Guided Backprop', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_gc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/GradCAM', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_ggc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/Guided GradCAM', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_gcpp, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/GradCAM++', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_sc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Inception (Tensor)/ScoreCAM', label + '_saliency_map.pt'))\n","\n","end_time = time.time()\n","execution_time = end_time - start_time\n","\n","print(\"Execution time:\", execution_time, \"seconds\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"taDkctMVNTsU","executionInfo":{"status":"ok","timestamp":1689784469335,"user_tz":240,"elapsed":153289,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"}},"outputId":"d47ef6cd-f394-426b-f7c8-37176aa2b4dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/captum/attr/_core/guided_backprop_deconvnet.py:64: UserWarning: Setting backward hooks on ReLU activations.The hooks will be removed after the attribution is finished\n","  warnings.warn(\n","<ipython-input-14-374470dc467b>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  cam = torch.tensor(cam[0])\n","<ipython-input-14-374470dc467b>:56: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n","  cmap = cm.get_cmap(\"plasma\")\n"]},{"output_type":"stream","name":"stdout","text":["Processing image 10/78\n","Processing image 20/78\n","Processing image 30/78\n","Processing image 40/78\n","Processing image 50/78\n","Processing image 60/78\n","Processing image 70/78\n","Execution time: 152.68548130989075 seconds\n"]}]},{"cell_type":"markdown","source":["#Visualize"],"metadata":{"id":"wBcwkaz9oso9"}},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gbp)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Guided Backpropagation', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"AZGK9aHMcqv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Grad CAM', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"craFzcnDQO_T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_ggc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Guided Grad CAM', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"6APMbZ4NQQoK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gcpp)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Grad CAM++', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"ezmuOp65QSQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_sc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Score CAM', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"cHuDMqTwQT58"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Torchcam GradCAM\n","\n"],"metadata":{"id":"phRXMvV-F5yL"}},{"cell_type":"code","source":["from torchcam.methods import GradCAM, ScoreCAM, GradCAMpp\n","import torch\n","from torchvision.models import resnet50\n","from PIL import Image\n","from torchvision.models import resnet18\n","\n","model = torch.load('/content/drive/MyDrive/Saliency Map Research 2023/Models/pneumonia_inception.pt').eval()\n","model = model.to(device)\n","for label in lim_patientId:\n","\n","  path = os.path.join(root, label + '.dcm.jpg.png')\n","\n","  im = LoadImage(path)\n","  im_tensor = PreprocessImagesNOBATCH(im)\n","  predictions = model(im_tensor)\n","  predictions = predictions.detach().cpu().numpy()\n","  prediction_class = np.argmax(predictions[0])\n","  input_image = im_tensor\n","\n","  prediction_class = torch.tensor(prediction_class)\n","\n","  # Generate saliency map using Guided Backpropagation\n","  cam_extractor = GradCAM(model)\n","                          #target_layer = 'Mixed_7c.branch_pool.conv')\n","  #saliency_map = cam(input_image, prediction_class)  # Specify the target class index\n","\n","  out = model(input_image)\n","  cams = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","\n","  #with GradCAM(model) as cam_extractor:\n","  # Preprocess your data and feed it to the model\n","  #  out = model(input_image.unsqueeze(0))\n","  # Retrieve the CAM by passing the class index and the model output\n","  #  activation_map = cam_extractor(out.squeeze(0).argmax().item(), out)"],"metadata":{"id":"oi-SzFK_5Tzx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for cam in cams:\n","  print(cam)"],"metadata":{"id":"3WNKFxJHh1en"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name, cam in zip(cam_extractor.target_names, cams):\n","  plt.imshow(cam.squeeze(0).cpu().numpy(), cmap = 'plasma')\n","  plt.axis('off')\n","  plt.title('TorchCAM GradCAM (No Smoothing)')\n","  plt.show()"],"metadata":{"id":"tAlMIdIyh6Ik"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchcam.utils import overlay_mask\n","from torchvision.transforms.functional import normalize, resize, to_pil_image\n","\n","# Overlayed on the image\n","for name, cam in zip(cam_extractor.target_names, cams):\n","  result = overlay_mask(to_pil_image(im), to_pil_image(cam.squeeze(0), mode='F'), colormap = 'plasma', alpha=0.5)\n","  plt.imshow(result); plt.axis('off'); plt.title(name); plt.show()"],"metadata":{"id":"vwzztcIyidqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(cam.squeeze(0))"],"metadata":{"id":"vRQGe8Slhd0U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cam_extractor.remove_hooks()"],"metadata":{"id":"5x7M_iZebKEw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from matplotlib import cm\n","\n","img = to_pil_image(im)\n","\n","cmap = cm.get_cmap(\"plasma\")\n","\n","mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","overlay = cmap(np.asarray(overlay) ** 2)\n","print(overlay)\n","overlay = overlay[:,:,:3]\n","#overlay = (255 * cmap(np.asarray(overlay) ** 2)[:, :, :3]).astype(np.uint8)\n","\n","plt.imshow(overlay, cmap = 'plasma')\n","plt.axis('off')\n","plt.title('TorchCAM GradCAM (Smoothing)')\n","plt.show()"],"metadata":{"id":"L2Ca_AyCZk_l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(overlay)"],"metadata":{"id":"aqRzXV-4dkKx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Torchcam Guided GradCAM"],"metadata":{"id":"yQDpimP3ZXau"}},{"cell_type":"code","source":["print(saliency_map_gbp)"],"metadata":{"id":"k_P9E8lv0K2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ggc = overlay * saliency_map_gbp\n","\n","ggc_mask_grayscale = saliency.VisualizeImageGrayscale(ggc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(ggc_mask_grayscale, title='Guided GradCAM Torchcam', ax=P.subplot(ROWS, COLS, 1))"],"metadata":{"id":"dLkXrlWggzuT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uWf_cjKyzz9i"},"execution_count":null,"outputs":[]}]}