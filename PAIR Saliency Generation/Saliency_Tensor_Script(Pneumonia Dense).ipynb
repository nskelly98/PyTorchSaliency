{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fNbyRzK5iTTx"},"outputs":[],"source":["!pip install saliency"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_V8rl6nOiIyz"},"outputs":[],"source":["\n","# Boilerplate imports.\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import PIL.Image\n","from matplotlib import pylab as P\n","import torch\n","import torchvision\n","from torchvision import models, transforms\n","from torchvision.models import Inception_V3_Weights\n","from torch.nn import ReLU\n","# From our repository.\n","import saliency.core as saliency\n","from PIL import Image\n","import os\n","\n","from torch.autograd import Variable\n","\n","%matplotlib inline\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KFSZ33GyUAiD"},"outputs":[],"source":["\n","##### Specify Device\n","\n","device = torch.device(\"cpu\")\n","\n","if torch.cuda.is_available():\n","   print(\"Training on GPU\")\n","   device = torch.device(\"cuda:0\")\n"]},{"cell_type":"code","source":["\n","# Boilerplate methods.\n","def ShowImage(im, title='', ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im)\n","    P.title(title)\n","\n","def ShowGrayscaleImage(im, title='', ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im, cmap=P.cm.gray, vmin=0, vmax=1)\n","    P.title(title)\n","\n","def ShowHeatMap(im, title, ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im, cmap='inferno')\n","    P.title(title)\n","\n","def LoadImage(file_path):\n","    im = PIL.Image.open(file_path).convert('RGB')\n","    im = im.resize((224, 224))\n","    im = np.asarray(im)\n","    return im\n","\n","transformer = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","def PreprocessImagesNOBATCH(images):\n","    # assumes input is 4-D, with range [0,255]\n","    images = np.array(images)\n","    images = images/255\n","    #print(images.shape)\n","    images = images.reshape(1,224,224,3)\n","    images = np.transpose(images, (0,3,1,2))\n","    images = torch.tensor(images, dtype=torch.float32)\n","    images = images.to(device)\n","    images = transformer.forward(images)\n","    return images.requires_grad_(True)\n","\n","def PreprocessImages(images):\n","    # assumes input is 4-D, with range [0,255]\n","    images = np.array(images)\n","    images = images/255\n","    #print(images.shape)\n","    #images = images.reshape(1,299,299,3)\n","    images = np.transpose(images, (0,3,1,2))\n","    images = torch.tensor(images, dtype=torch.float32)\n","    images = transformer.forward(images)\n","    return images.requires_grad_(True)\n"],"metadata":{"id":"JVJqMSakbb2O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model = torch.load('/content/drive/MyDrive/Saliency Map Research 2023/Models/pneumonia_dense.pt')\n","model = model.to(device)\n","eval_mode = model.eval()\n","\n","# Register hooks for Grad-CAM, which uses the last convolution layer\n","conv_layer = model.features.denseblock4.denselayer16.conv2\n","conv_layer_outputs = {}\n","def conv_layer_forward(m, i, o):\n","    # move the RGB dimension to the last dimension\n","    conv_layer_outputs[saliency.base.CONVOLUTION_LAYER_VALUES] = torch.movedim(o.cpu(), 1, 3).detach().numpy()\n","def conv_layer_backward(m, i, o):\n","    # move the RGB dimension to the last dimension\n","    conv_layer_outputs[saliency.base.CONVOLUTION_OUTPUT_GRADIENTS] = torch.movedim(o[0].cpu(), 1, 3).detach().numpy()\n","\n","conv_layer.register_forward_hook(conv_layer_forward)\n","conv_layer.register_full_backward_hook(conv_layer_backward)\n"],"metadata":{"id":"T7R9boXKbdxo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class_idx_str = 'class_idx_str'\n","def call_model_function(images, call_model_args=None, expected_keys=None):\n","    images = PreprocessImages(images)\n","    images = images.to(device)\n","    target_class_idx =  call_model_args[class_idx_str]\n","    output = model(images)\n","    m = torch.nn.Softmax(dim=1)\n","    output = m(output)\n","    if saliency.base.INPUT_OUTPUT_GRADIENTS in expected_keys:\n","        outputs = output[:,target_class_idx]\n","        grads = torch.autograd.grad(outputs, images, grad_outputs=torch.ones_like(outputs))\n","        grads = torch.movedim(grads[0].cpu(), 1, 3)\n","        gradients = grads.detach().numpy()\n","        return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n","    else:\n","        one_hot = torch.zeros_like(output)\n","        one_hot[:,target_class_idx] = 1\n","        model.zero_grad()\n","        output.backward(gradient=one_hot, retain_graph=True)\n","        return conv_layer_outputs\n"],"metadata":{"id":"H8tnu8Q0buDl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Load the image\n","path = '/content/drive/MyDrive/Saliency Map Research 2023/Pneumonia Dataset/stage_2_train_images_png/0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm.jpg.png'\n","im_orig = LoadImage(path)\n","im_tensor = PreprocessImagesNOBATCH(im_orig)\n","# Show the image\n","ShowImage(im_orig)\n","\n","predictions = model(im_tensor)\n","predictions = predictions.detach().cpu().numpy()\n","prediction_class = np.argmax(predictions[0])\n","call_model_args = {class_idx_str: prediction_class}\n","\n","print(\"Prediction class: \" + str(prediction_class))\n","im = im_orig\n","#.astype(np.float)\n"],"metadata":{"id":"ZnCunrfNby3d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Saliency Maps\n"],"metadata":{"id":"HCG0DxxTb_iv"}},{"cell_type":"code","source":["\n","#Count files in directory\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/IG'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"Number of files:\", file_count)\n"],"metadata":{"id":"xbC1gis6ry4o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_labels(file_path):\n","  labels = pd.read_csv(file_path)\n","  labels = labels.drop(['x','y','width','height'], axis=1)\n","  labels = labels.drop_duplicates(\"patientId\")\n","  return labels\n","\n","labels = make_labels(\"/content/drive/MyDrive/Saliency Map Research 2023/Pneumonia Dataset/Pneumonia_Labels_Final_2.csv\")\n","patientId = labels['patientId'].tolist()\n","lim_patientId = patientId\n","\n","root = '/content/drive/MyDrive/Saliency Map Research 2023/Pneumonia Dataset/stage_2_train_images_png'"],"metadata":{"id":"7prj0FFCmmVd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# Original patient IDs\n","patientId = labels['patientId'].tolist()\n","lim_patientId = patientId\n","\n","# Directory path\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Dense (Tensor)/Grad'\n","\n","# Get the list of patient IDs in the directory\n","file_names = os.listdir(directory_path)\n","directory_patient_ids = [file_name.split('_')[0] for file_name in file_names]\n","\n","# Find the missing patient IDs\n","missing_patient_ids = [patient_id for patient_id in lim_patientId if patient_id not in directory_patient_ids]\n","\n","print(\"Missing patient IDs:\", missing_patient_ids)\n","print(len(missing_patient_ids))"],"metadata":{"id":"X8aygZ69QcS2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#lim_patientId = lim_patientId[14310:]"],"metadata":{"id":"GONXuimZQqgj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import time\n","\n","start_time = time.time()\n","\n","counter = 0\n","\n","for label in patientId:\n","\n","  counter += 1  # Increment the counter\n","\n","  if counter % 10 == 0:  # Display the count for every 10th image\n","       print(f\"Processing image {counter}/{len(lim_patientId)}\")\n","\n","  path = os.path.join(root, label + '.dcm.jpg.png')\n","\n","  im = LoadImage(path)\n","  im_tensor = PreprocessImagesNOBATCH(im)\n","  predictions = model(im_tensor)\n","  predictions = predictions.detach().cpu().numpy()\n","  prediction_class = np.argmax(predictions[0])\n","  call_model_args = {class_idx_str: prediction_class}\n","\n","  ######Grad######\n","\n","  # Construct the saliency object. This alone doesn't do anthing.\n","  gradient_saliency = saliency.GradientSaliency()\n","  integrated_gradients = saliency.IntegratedGradients()\n","  xrai_object = saliency.XRAI()\n","  grad_cam = saliency.GradCam()\n","\n","  # Compute the vanilla mask and the smoothed mask.\n","  vanilla_mask_3d = gradient_saliency.GetMask(im, call_model_function, call_model_args)\n","  smoothgrad_mask_3d = gradient_saliency.GetSmoothedMask(im, call_model_function, call_model_args)\n","\n","  ######IG######\n","\n","  # Baseline is a black image.\n","  baseline = np.zeros(im.shape)\n","\n","  # Compute the vanilla mask and the smoothed mask.\n","  vanilla_integrated_gradients_mask_3d = integrated_gradients.GetMask(\n","    im, call_model_function, call_model_args, x_steps=25, x_baseline=baseline, batch_size=20)\n","  # Smoothed mask for integrated gradients will take a while since we are doing nsamples * nsamples computations.\n","  smoothgrad_integrated_gradients_mask_3d = integrated_gradients.GetSmoothedMask(\n","    im, call_model_function, call_model_args, x_steps=25, x_baseline=baseline, batch_size=20)\n","\n","  #####XRAI######\n","\n","  # Create XRAIParameters and set the algorithm to fast mode which will produce an approximate result.\n","  xrai_params = saliency.XRAIParameters()\n","  xrai_params.algorithm = 'fast'\n","\n","  # Compute XRAI attributions with fast algorithm\n","  xrai_attributions_fast = xrai_object.GetMask(im, call_model_function, call_model_args, extra_parameters=xrai_params, batch_size=20)\n","\n","  ######GradCAM######\n","\n","  # Compute the Grad-CAM mask and Smoothgrad+Grad-CAM mask.\n","  grad_cam_mask_3d = grad_cam.GetMask(im, call_model_function, call_model_args)\n","  #smooth_grad_cam_mask_3d = grad_cam.GetSmoothedMask(im, call_model_function, call_model_args)\n","\n","  #Save the arrays\n","  #output_path = os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Dense (Heat Map)/ScoreCAM', label + '_saliency_map.jpg')\n","  torch.save(vanilla_mask_3d, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/Grad', label + '_saliency_map.pt'))\n","  torch.save(smoothgrad_mask_3d, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/Smooth Grad', label + '_saliency_map.pt'))\n","  torch.save(vanilla_integrated_gradients_mask_3d, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/IG', label + '_saliency_map.pt'))\n","  torch.save(smoothgrad_integrated_gradients_mask_3d, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/Smooth IG', label + '_saliency_map.pt'))\n","  torch.save(xrai_attributions_fast, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/XRAI', label + '_saliency_map.pt'))\n","  torch.save(grad_cam_mask_3d, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/GradCAM', label + '_saliency_map.pt'))\n","\n","end_time = time.time()\n","execution_time = end_time - start_time\n","\n","print(\"Execution time:\", execution_time, \"seconds\")\n"],"metadata":{"id":"cjSQJazJknip"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Visualization"],"metadata":{"id":"yGmLJnrpx1OJ"}},{"cell_type":"code","source":["\n","# Construct the saliency object. This alone doesn't do anthing.\n","gradient_saliency = saliency.GradientSaliency()\n","\n","# Compute the vanilla mask and the smoothed mask.\n","vanilla_mask_3d = gradient_saliency.GetMask(im, call_model_function, call_model_args)\n","smoothgrad_mask_3d = gradient_saliency.GetSmoothedMask(im, call_model_function, call_model_args)\n","\n","# Call the visualization methods to convert the 3D tensors to 2D grayscale.\n","vanilla_mask_grayscale = saliency.VisualizeImageGrayscale(vanilla_mask_3d)\n","smoothgrad_mask_grayscale = saliency.VisualizeImageGrayscale(smoothgrad_mask_3d)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 2\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowGrayscaleImage(vanilla_mask_grayscale, title='Vanilla Gradient', ax=P.subplot(ROWS, COLS, 1))\n","ShowGrayscaleImage(smoothgrad_mask_grayscale, title='SmoothGrad', ax=P.subplot(ROWS, COLS, 2))\n"],"metadata":{"id":"bV1Q5h4-h2FI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Construct the saliency object. This alone doesn't do anthing.\n","integrated_gradients = saliency.IntegratedGradients()\n","\n","# Baseline is a black image.\n","baseline = np.zeros(im.shape)\n","\n","# Compute the vanilla mask and the smoothed mask.\n","vanilla_integrated_gradients_mask_3d = integrated_gradients.GetMask(\n","  im, call_model_function, call_model_args, x_steps=25, x_baseline=baseline, batch_size=20)\n","# Smoothed mask for integrated gradients will take a while since we are doing nsamples * nsamples computations.\n","smoothgrad_integrated_gradients_mask_3d = integrated_gradients.GetSmoothedMask(\n","  im, call_model_function, call_model_args, x_steps=25, x_baseline=baseline, batch_size=20)\n","\n","# Call the visualization methods to convert the 3D tensors to 2D grayscale.\n","vanilla_mask_grayscale = saliency.VisualizeImageGrayscale(vanilla_integrated_gradients_mask_3d)\n","smoothgrad_mask_grayscale = saliency.VisualizeImageGrayscale(smoothgrad_integrated_gradients_mask_3d)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 2\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowGrayscaleImage(vanilla_mask_grayscale, title='Vanilla Integrated Gradients', ax=P.subplot(ROWS, COLS, 1))\n","ShowGrayscaleImage(smoothgrad_mask_grayscale, title='Smoothgrad Integrated Gradients', ax=P.subplot(ROWS, COLS, 2))\n"],"metadata":{"id":"cv7tELQJjqk6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Construct the saliency object. This alone doesn't do anthing.\n","xrai_object = saliency.XRAI()\n","\n","# Create XRAIParameters and set the algorithm to fast mode which will produce an approximate result.\n","xrai_params = saliency.XRAIParameters()\n","xrai_params.algorithm = 'fast'\n","\n","# Compute XRAI attributions with fast algorithm\n","xrai_attributions_fast = xrai_object.GetMask(im, call_model_function, call_model_args, extra_parameters=xrai_params, batch_size=20)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 3\n","UPSCALE_FACTOR = 20\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Show original image\n","ShowImage(im_orig, title='Original Image', ax=P.subplot(ROWS, COLS, 1))\n","\n","# Show XRAI heatmap attributions\n","ShowHeatMap(xrai_attributions_fast, title='XRAI Heatmap', ax=P.subplot(ROWS, COLS, 2))\n","\n","# Show most salient 30% of the image\n","mask = xrai_attributions_fast >= np.percentile(xrai_attributions_fast, 70)\n","im_mask = np.array(im_orig)\n","im_mask[~mask] = 0\n","ShowImage(im_mask, 'Top 30%', ax=P.subplot(ROWS, COLS, 3))\n"],"metadata":{"id":"I1bLqQ-gjw9E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Compare Grad-CAM and Smoothgrad with Grad-CAM.\n","\n","# Construct the saliency object. This alone doesn't do anthing.\n","grad_cam = saliency.GradCam()\n","\n","# Compute the Grad-CAM mask and Smoothgrad+Grad-CAM mask.\n","grad_cam_mask_3d = grad_cam.GetMask(im, call_model_function, call_model_args)\n","smooth_grad_cam_mask_3d = grad_cam.GetSmoothedMask(im, call_model_function, call_model_args)\n","\n","# Call the visualization methods to convert the 3D tensors to 2D grayscale.\n","grad_cam_mask_grayscale = saliency.VisualizeImageGrayscale(grad_cam_mask_3d)\n","smooth_grad_cam_mask_grayscale = saliency.VisualizeImageGrayscale(smooth_grad_cam_mask_3d)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 2\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowGrayscaleImage(grad_cam_mask_grayscale, title='Grad-CAM', ax=P.subplot(ROWS, COLS, 1))\n","ShowGrayscaleImage(smooth_grad_cam_mask_grayscale, title='Smoothgrad Grad-CAM', ax=P.subplot(ROWS, COLS, 2))\n"],"metadata":{"id":"_S9erJN7j0RJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Y0I310suXvDt"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1wcuEDUIKSq6-QwEWbvPeHB6vN7g8aGWd","timestamp":1686687725291}],"gpuType":"T4","mount_file_id":"1d_KdjE8f-zTpLXdY-FO5ygkF1WVLlLiN","authorship_tag":"ABX9TyOLTBufoO6v7ZBQALsoLOus"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}