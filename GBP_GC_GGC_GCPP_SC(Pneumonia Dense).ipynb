{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19405,"status":"ok","timestamp":1703780752441,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"},"user_tz":300},"id":"utu70TUTXlhY","outputId":"b44342f3-3483-4789-b770-55a06812b8ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchcam\n","  Downloading torchcam-0.4.0-py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m571.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchcam) (2.1.0+cu121)\n","Requirement already satisfied: numpy<2.0.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchcam) (1.23.5)\n","Requirement already satisfied: Pillow!=9.2.0,>=8.4.0 in /usr/local/lib/python3.10/dist-packages (from torchcam) (9.4.0)\n","Requirement already satisfied: matplotlib<4.0.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from torchcam) (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (2.8.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (2.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.0->torchcam) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->torchcam) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.0.0->torchcam) (1.3.0)\n","Installing collected packages: torchcam\n","Successfully installed torchcam-0.4.0\n"]}],"source":["!pip install torchcam"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9309,"status":"ok","timestamp":1703780761747,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"},"user_tz":300},"id":"gs7xY9gndL3c","outputId":"afe5e3bb-6bce-46e5-8514-a81c1a4e24bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting saliency\n","  Downloading saliency-0.2.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from saliency) (1.23.5)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from saliency) (0.19.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (1.11.4)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (3.2.1)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (9.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (2023.12.9)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (1.5.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->saliency) (23.2)\n","Installing collected packages: saliency\n","Successfully installed saliency-0.2.0\n"]}],"source":["!pip install saliency"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12250,"status":"ok","timestamp":1703780773975,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"},"user_tz":300},"id":"Y_sxx_LU9nrL","outputId":"0f87b758-5143-448f-aaf3-8ee4df9c7051"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting captum\n","  Downloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from captum) (4.66.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n","Installing collected packages: captum\n","Successfully installed captum-0.7.0\n"]}],"source":["!pip install captum"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KaA-upXlpz8v"},"outputs":[],"source":["import torch\n","from torchvision import models, transforms\n","from captum.attr import GuidedBackprop\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","import pandas as pd\n","from captum.attr import GuidedGradCam\n","import os\n","from matplotlib import pylab as P\n","import PIL.Image\n","import saliency.core as saliency"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1703780786763,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"},"user_tz":300},"id":"yMPr1Kt4XIXC","outputId":"1a678e10-4c3f-41b3-a47e-61aa3e9dbce8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training on GPU\n"]}],"source":["\n","##### Specify Device\n","\n","device = torch.device(\"cpu\")\n","\n","if torch.cuda.is_available():\n","   print(\"Training on GPU\")\n","   device = torch.device(\"cuda:0\")\n"]},{"cell_type":"markdown","metadata":{"id":"tjJh7mFBwyPV"},"source":["#Preliminary"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6931747,"status":"ok","timestamp":1703787718483,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"},"user_tz":300},"id":"W3dB2Stb6-7h","outputId":"902a36a2-0648-479b-bb34-b6a7bb7aba7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5mIX7MSvZrMV"},"outputs":[],"source":["\n","# Boilerplate methods.\n","def ShowImage(im, title='', ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im)\n","    P.title(title)\n","\n","def ShowGrayscaleImage(im, title='', ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im, cmap=P.cm.gray, vmin=0, vmax=1)\n","    P.title(title)\n","\n","def ShowHeatMap(im, title, ax=None):\n","    if ax is None:\n","        P.figure()\n","    P.axis('off')\n","    P.imshow(im, cmap='inferno')\n","    P.title(title)\n","\n","def LoadImage(file_path):\n","    im = PIL.Image.open(file_path).convert('RGB')\n","    im = im.resize((224, 224))\n","    im = np.asarray(im)\n","    return im\n","\n","transformer = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","def PreprocessImagesNOBATCH(images):\n","    # assumes input is 4-D, with range [0,255]\n","    images = np.array(images)\n","    images = images/255\n","    #print(images.shape)\n","    images = images.reshape(1,224,224,3)\n","    images = np.transpose(images, (0,3,1,2))\n","    images = torch.tensor(images, dtype=torch.float32)\n","    images = images.to(device)\n","    images = transformer.forward(images)\n","    return images.requires_grad_(True)\n","\n","def PreprocessImages(images):\n","    # assumes input is 4-D, with range [0,255]\n","    images = np.array(images)\n","    images = images/255\n","    #print(images.shape)\n","    #images = images.reshape(1,299,299,3)\n","    images = np.transpose(images, (0,3,1,2))\n","    images = torch.tensor(images, dtype=torch.float32)\n","    images = transformer.forward(images)\n","    return images.requires_grad_(True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2761,"status":"ok","timestamp":1703787721242,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"},"user_tz":300},"id":"_gyDRXeOp57b","outputId":"124d556f-6940-4c9a-acb7-b5d2f62fb4cf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (6): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (7): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (8): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (9): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (10): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (11): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (12): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (13): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (14): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (15): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (16): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (17): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (18): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (19): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (20): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (21): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (22): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":8}],"source":["\n","# Load the pre-trained model\n","model = torch.load('/content/drive/MyDrive/Saliency Map Research 2023/Models/pneumonia_dense.pt')\n","model=model.to(device)\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703787721242,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"},"user_tz":300},"id":"BETYuRPFvGsO","outputId":"69cfd763-5309-4503-f922-d02e98c3597a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.utils.hooks.RemovableHandle at 0x7a787311df00>"]},"metadata":{},"execution_count":9}],"source":["# Register hooks for Grad-CAM, which uses the last convolution layer\n","conv_layer = model.features.denseblock4.denselayer16.conv2\n","conv_layer_outputs = {}\n","def conv_layer_forward(m, i, o):\n","    # move the RGB dimension to the last dimension\n","    conv_layer_outputs[saliency.base.CONVOLUTION_LAYER_VALUES] = torch.movedim(o.cpu(), 1, 3).detach().numpy()\n","def conv_layer_backward(m, i, o):\n","    # move the RGB dimension to the last dimension\n","    conv_layer_outputs[saliency.base.CONVOLUTION_OUTPUT_GRADIENTS] = torch.movedim(o[0].cpu(), 1, 3).detach().numpy()\n","\n","conv_layer.register_forward_hook(conv_layer_forward)\n","conv_layer.register_full_backward_hook(conv_layer_backward)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9kJTYgo9osaE"},"outputs":[],"source":["class_idx_str = 'class_idx_str'\n","def call_model_function(images, call_model_args=None, expected_keys=None):\n","    images = PreprocessImages(images)\n","    images = images.to(device)\n","    target_class_idx =  call_model_args[class_idx_str]\n","    output = model(images)\n","    m = torch.nn.Softmax(dim=1)\n","    output = m(output)\n","    if saliency.base.INPUT_OUTPUT_GRADIENTS in expected_keys:\n","        outputs = output[:,target_class_idx]\n","        grads = torch.autograd.grad(outputs, images, grad_outputs=torch.ones_like(outputs))\n","        grads = torch.movedim(grads[0].cpu(), 1, 3)\n","        gradients = grads.detach().numpy()\n","        return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n","    else:\n","        one_hot = torch.zeros_like(output)\n","        one_hot[:,target_class_idx] = 1\n","        model.zero_grad()\n","        output.backward(gradient=one_hot, retain_graph=True)\n","        return conv_layer_outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118816,"status":"ok","timestamp":1703787840056,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"},"user_tz":300},"id":"Xgw-d8GWAi0j","outputId":"81f02983-c706-4680-d74d-022288b9e144"},"outputs":[{"output_type":"stream","name":"stdout","text":["GradCAM: 14861\n","Guided Backprop: 13392\n","Guided GradCAM 13392\n","GradCAM++: 13392\n","ScoreCAM: 13392\n"]}],"source":["#Count files in directory\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/GradCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"GradCAM:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/Guided Backprop'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"Guided Backprop:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/Guided GradCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"Guided GradCAM\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/GradCAM++'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"GradCAM++:\", file_count)\n","\n","directory_path = '/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/ScoreCAM'\n","file_count = 0\n","\n","# Iterate over all the files and directories in the given directory\n","for root, dirs, files in os.walk(directory_path):\n","    file_count += len(files)\n","\n","print(\"ScoreCAM:\", file_count)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j3ComgyNPF5A"},"outputs":[],"source":["\n","def make_labels(file_path):\n","  labels = pd.read_csv(file_path)\n","  labels = labels.drop(['x','y','width','height'], axis=1)\n","  labels = labels.drop_duplicates(\"patientId\")\n","  return labels\n","\n","labels = make_labels(\"/content/drive/MyDrive/Saliency Map Research 2023/Pneumonia Dataset/Pneumonia_Labels_Final_2.csv\")\n","patientId = labels['patientId'].tolist()\n","#lim_patientId = patientId[13390:]\n","\n","root = '/content/drive/MyDrive/Saliency Map Research 2023/Pneumonia Dataset/stage_2_train_images_png'\n"]},{"cell_type":"markdown","metadata":{"id":"tKHB4Gzqj3_q"},"source":["#Script\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"taDkctMVNTsU","executionInfo":{"status":"ok","timestamp":1703804888960,"user_tz":300,"elapsed":16610403,"user":{"displayName":"Nolan Skelly","userId":"06424341206212226691"}},"outputId":"c95a6f29-8235-4800-dd80-eb39768b24b4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/captum/attr/_core/guided_backprop_deconvnet.py:64: UserWarning: Setting backward hooks on ReLU activations.The hooks will be removed after the attribution is finished\n","  warnings.warn(\n","<ipython-input-16-d4df66c2ef5d>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  cam = torch.tensor(cam[0])\n","<ipython-input-16-d4df66c2ef5d>:56: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n","  cmap = cm.get_cmap(\"plasma\")\n","<ipython-input-16-d4df66c2ef5d>:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  cam = torch.tensor(cam[0])\n","<ipython-input-16-d4df66c2ef5d>:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  cam = torch.tensor(cam[0])\n"]},{"output_type":"stream","name":"stdout","text":["Processing image 13400/14861\n","Processing image 13410/14861\n","Processing image 13420/14861\n","Processing image 13430/14861\n","Processing image 13440/14861\n","Processing image 13450/14861\n","Processing image 13460/14861\n","Processing image 13470/14861\n","Processing image 13480/14861\n","Processing image 13490/14861\n","Processing image 13500/14861\n","Processing image 13510/14861\n","Processing image 13520/14861\n","Processing image 13530/14861\n","Processing image 13540/14861\n","Processing image 13550/14861\n","Processing image 13560/14861\n","Processing image 13570/14861\n","Processing image 13580/14861\n","Processing image 13590/14861\n","Processing image 13600/14861\n","Processing image 13610/14861\n","Processing image 13620/14861\n","Processing image 13630/14861\n","Processing image 13640/14861\n","Processing image 13650/14861\n","Processing image 13660/14861\n","Processing image 13670/14861\n","Processing image 13680/14861\n","Processing image 13690/14861\n","Processing image 13700/14861\n","Processing image 13710/14861\n","Processing image 13720/14861\n","Processing image 13730/14861\n","Processing image 13740/14861\n","Processing image 13750/14861\n","Processing image 13760/14861\n","Processing image 13770/14861\n","Processing image 13780/14861\n","Processing image 13790/14861\n","Processing image 13800/14861\n","Processing image 13810/14861\n","Processing image 13820/14861\n","Processing image 13830/14861\n","Processing image 13840/14861\n","Processing image 13850/14861\n","Processing image 13860/14861\n","Processing image 13870/14861\n","Processing image 13880/14861\n","Processing image 13890/14861\n","Processing image 13900/14861\n","Processing image 13910/14861\n","Processing image 13920/14861\n","Processing image 13930/14861\n","Processing image 13940/14861\n","Processing image 13950/14861\n","Processing image 13960/14861\n","Processing image 13970/14861\n","Processing image 13980/14861\n","Processing image 13990/14861\n","Processing image 14000/14861\n","Processing image 14010/14861\n","Processing image 14020/14861\n","Processing image 14030/14861\n","Processing image 14040/14861\n","Processing image 14050/14861\n","Processing image 14060/14861\n","Processing image 14070/14861\n","Processing image 14080/14861\n","Processing image 14090/14861\n","Processing image 14100/14861\n","Processing image 14110/14861\n","Processing image 14120/14861\n","Processing image 14130/14861\n","Processing image 14140/14861\n","Processing image 14150/14861\n","Processing image 14160/14861\n","Processing image 14170/14861\n","Processing image 14180/14861\n","Processing image 14190/14861\n","Processing image 14200/14861\n","Processing image 14210/14861\n","Processing image 14220/14861\n","Processing image 14230/14861\n","Processing image 14240/14861\n","Processing image 14250/14861\n","Processing image 14260/14861\n","Processing image 14270/14861\n","Processing image 14280/14861\n","Processing image 14290/14861\n","Processing image 14300/14861\n","Processing image 14310/14861\n","Processing image 14320/14861\n","Processing image 14330/14861\n","Processing image 14340/14861\n","Processing image 14350/14861\n","Processing image 14360/14861\n","Processing image 14370/14861\n","Processing image 14380/14861\n","Processing image 14390/14861\n","Processing image 14400/14861\n","Processing image 14410/14861\n","Processing image 14420/14861\n","Processing image 14430/14861\n","Processing image 14440/14861\n","Processing image 14450/14861\n","Processing image 14460/14861\n","Processing image 14470/14861\n","Processing image 14480/14861\n","Processing image 14490/14861\n","Processing image 14500/14861\n","Processing image 14510/14861\n","Processing image 14520/14861\n","Processing image 14530/14861\n","Processing image 14540/14861\n","Processing image 14550/14861\n","Processing image 14560/14861\n","Processing image 14570/14861\n","Processing image 14580/14861\n","Processing image 14590/14861\n","Processing image 14600/14861\n","Processing image 14610/14861\n","Processing image 14620/14861\n","Processing image 14630/14861\n","Processing image 14640/14861\n","Processing image 14650/14861\n","Processing image 14660/14861\n","Processing image 14670/14861\n","Processing image 14680/14861\n","Processing image 14690/14861\n","Processing image 14700/14861\n","Processing image 14710/14861\n","Processing image 14720/14861\n","Processing image 14730/14861\n","Processing image 14740/14861\n","Processing image 14750/14861\n","Processing image 14760/14861\n","Processing image 14770/14861\n","Processing image 14780/14861\n","Processing image 14790/14861\n","Processing image 14800/14861\n","Processing image 14810/14861\n","Processing image 14820/14861\n","Processing image 14830/14861\n","Processing image 14840/14861\n","Processing image 14850/14861\n","Processing image 14860/14861\n","Execution time: 16609.967379570007 seconds\n"]}],"source":["from torchcam.methods import GradCAM, ScoreCAM, GradCAMpp\n","from torchcam.utils import overlay_mask\n","from torchvision.transforms.functional import normalize, resize, to_pil_image\n","from matplotlib import cm\n","import time\n","\n","model = torch.load('/content/drive/MyDrive/Saliency Map Research 2023/Models/pneumonia_dense.pt').eval()\n","model = model.to(device)\n","\n","start_time = time.time()\n","\n","counter = 0\n","\n","model.requires_grad_(True)\n","\n","for label in patientId:\n","\n","  counter += 1  # Increment the counter\n","\n","  if counter % 10 == 0:  # Display the count for every 10th image\n","       print(f\"Processing image {counter}/{len(patientId)}\")\n","\n","  path = os.path.join(root, label + '.dcm.jpg.png')\n","\n","  im = LoadImage(path)\n","  im_tensor = PreprocessImagesNOBATCH(im)\n","  predictions = model(im_tensor)\n","  predictions = predictions.detach().cpu().numpy()\n","  prediction_class = np.argmax(predictions[0])\n","  input_image = im_tensor\n","\n","  prediction_class = torch.tensor(prediction_class)\n","\n","  if torch.cuda.is_available():\n","      input_image = input_image.cuda()  # Move input tensor to GPU\n","\n","  ######Guided Back Propagation######\n","\n","  # Generate saliency map using Guided Backpropagation\n","  guided_backprop = GuidedBackprop(model)\n","  guided_backprop_map = guided_backprop.attribute(input_image, target=prediction_class)  # Specify the target class index\n","\n","  saliency_map_gbp = np.transpose(guided_backprop_map.squeeze().cpu().numpy(), (1, 2, 0))\n","\n","  ######GradCAM######\n","\n","  cam_extractor = GradCAM(model, target_layer=model.layer4[-1].conv3)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  img = to_pil_image(im)\n","\n","  cmap = cm.get_cmap(\"plasma\")\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_gc = overlay\n","\n","  ######Guided GradCAM######\n","\n","  saliency_map_ggc = saliency_map_gbp * saliency_map_gc\n","\n","  cam_extractor.remove_hooks()\n","\n","  ######GradCAM++######\n","\n","  cam_extractor = GradCAMpp(model, target_layer=model.layer4[-1].conv3)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_gcpp = overlay\n","\n","  cam_extractor.remove_hooks()\n","\n","  ######ScoreCAM######\n","\n","  cam_extractor = ScoreCAM(model, target_layer=model.layer4[-1].conv3)\n","\n","  out = model(input_image)\n","  cam = cam_extractor(out.squeeze(0).argmax().item(), out)\n","\n","  cam = torch.tensor(cam[0])\n","\n","  mask = to_pil_image(cam.squeeze(0), mode='F')\n","\n","  overlay = mask.resize(img.size, resample=Image.BICUBIC)\n","  overlay = cmap(np.asarray(overlay) ** 2)\n","  overlay = overlay[:,:,:3]\n","\n","  saliency_map_sc = overlay\n","\n","  cam_extractor.remove_hooks()\n","\n","  #Save the arrays\n","  torch.save(saliency_map_gbp, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/Guided Backprop', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_gc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/GradCAM', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_ggc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/Guided GradCAM', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_gcpp, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/GradCAM++', label + '_saliency_map.pt'))\n","  torch.save(saliency_map_sc, os.path.join('/content/drive/MyDrive/Saliency Map Research 2023/SaliencyMaps/Pneumonia Resnet (Tensor)/ScoreCAM', label + '_saliency_map.pt'))\n","\n","end_time = time.time()\n","execution_time = end_time - start_time\n","\n","print(\"Execution time:\", execution_time, \"seconds\")\n"]},{"cell_type":"markdown","metadata":{"id":"wBcwkaz9oso9"},"source":["#Visualize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AZGK9aHMcqv0"},"outputs":[],"source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gbp)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Guided Backpropagation', ax=P.subplot(ROWS, COLS, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"craFzcnDQO_T"},"outputs":[],"source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Grad CAM', ax=P.subplot(ROWS, COLS, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6APMbZ4NQQoK"},"outputs":[],"source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_ggc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Guided Grad CAM', ax=P.subplot(ROWS, COLS, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ezmuOp65QSQD"},"outputs":[],"source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_gcpp)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Grad CAM++', ax=P.subplot(ROWS, COLS, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cHuDMqTwQT58"},"outputs":[],"source":["gbp_mask_grayscale = saliency.VisualizeImageGrayscale(saliency_map_sc)\n","\n","# Set up matplot lib figures.\n","ROWS = 1\n","COLS = 1\n","UPSCALE_FACTOR = 10\n","P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n","\n","# Render the saliency masks.\n","ShowHeatMap(gbp_mask_grayscale, title='Score CAM', ax=P.subplot(ROWS, COLS, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OIj9RNhjr-oG"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1RJbPwa-XXLbZx9HxqVXBQFtVFqfwij15","authorship_tag":"ABX9TyOXmzdViFFKTFiJPgL2cXJE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}